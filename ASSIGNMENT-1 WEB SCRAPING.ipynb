{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3775940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7816c4",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22630566",
   "metadata": {},
   "source": [
    "# 1. Write a python program to display all the header tags from wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f2b730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5a8d74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "f31af1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e845584",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_H1=[]\n",
    "for i in soup.find_all('h1'):\n",
    "    header_H1.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1f900d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Main Page', 'Welcome to Wikipedia']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96b4b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_H2=[]\n",
    "for i in soup.find_all('h2'):\n",
    "    header_H2.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4deaeb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages',\n",
       " 'Navigation menu']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_H2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3793823",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_H3=[]\n",
    "for i in soup.find_all('h3'):\n",
    "    header_H3.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb186eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nPersonal tools\\n',\n",
       " '\\nNamespaces\\n',\n",
       " '\\nViews\\n',\n",
       " '\\nSearch\\n',\n",
       " '\\nNavigation\\n',\n",
       " '\\nContribute\\n',\n",
       " '\\nTools\\n',\n",
       " '\\nPrint/export\\n',\n",
       " '\\nIn other projects\\n',\n",
       " '\\nLanguages\\n']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_H3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64f8d9e",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db7a11f",
   "metadata": {},
   "source": [
    "# 2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a26c969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page3 = requests.get('http://www.imdb.com/chart/top')\n",
    "soup = BeautifulSoup(page3.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fe426d",
   "metadata": {},
   "source": [
    "Find Movie Name and Delete the unnecessary elements ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6397d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "mov=[]\n",
    "for i in soup.find_all('td',class_=\"titleColumn\"):\n",
    "    for i in soup.find_all('a'):\n",
    "        mov.append(i.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760236c4",
   "metadata": {},
   "source": [
    "Remove \"\\n\" from string and unnecessary elements from list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67ac4584",
   "metadata": {},
   "outputs": [],
   "source": [
    "del mov[0:49]\n",
    "\n",
    "for i in mov:\n",
    "    if i==' \\n':\n",
    "        mov.remove(i)\n",
    "\n",
    "del mov[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f86d009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(mov))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee9928d",
   "metadata": {},
   "source": [
    "Find Year of Release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30ed34f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z=[]\n",
    "for i in soup.find_all('td',class_=\"titleColumn\"):\n",
    "    for i in soup.find_all('span',class_=\"secondaryInfo\"):\n",
    "        z.append(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4836eb91",
   "metadata": {},
   "source": [
    "Delete unnecessary elements from list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae4a4892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "del z[100:]\n",
    "\n",
    "k=[]\n",
    "for i in z:\n",
    "    k.append(i[1:-1])\n",
    "    \n",
    "print(len(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11feade7",
   "metadata": {},
   "source": [
    "Find Rating and Delete unnecessary elements from list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "198e169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "mo=[]\n",
    "for i in soup.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "        mo.append(i.text)\n",
    "del mo[100:]\n",
    "print(len(mo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2152c1da",
   "metadata": {},
   "source": [
    "Remove \"\\n\" from string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ba72b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=[]\n",
    "for i in mo:\n",
    "    m.append(i[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f08fe894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movies Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Movies Name  Year  Ratings\n",
       "0  The Shawshank Redemption  1994     9.2\n",
       "1             The Godfather  1972     9.2\n",
       "2           The Dark Knight  2008     9.0\n",
       "3     The Godfather Part II  1974     9.0\n",
       "4              12 Angry Men  1957     8.9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "t=pd.DataFrame({\"Movies Name \":mov,\"Year \":k,\"Ratings\":m})\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d449fc",
   "metadata": {},
   "source": [
    "# 3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7f08ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page3b = requests.get('https://www.imdb.com/india/top-rated-indian-movies/?sort=ir,desc&mode=simple&page=1')\n",
    "page3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fed52dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page3b.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743fdaa6",
   "metadata": {},
   "source": [
    "Find Movie Name and Delete the unnecessary elements ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "721ee060",
   "metadata": {},
   "outputs": [],
   "source": [
    "h=[]\n",
    "for i in soup.find_all('td',class_=\"titleColumn\"):\n",
    "    for i in soup.find_all('a'):\n",
    "        h.append(i.text)\n",
    "        \n",
    "del h[0:55]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668196df",
   "metadata": {},
   "source": [
    "Remove \"\\n\" from string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fce7a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in h:\n",
    "    if i==' \\n':\n",
    "        h.remove(i)\n",
    "del h[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15ed0424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c192c32e",
   "metadata": {},
   "source": [
    "Find Year of release and delete unnecessary elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "329fe96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "z=[]\n",
    "for i in soup.find_all('td',class_=\"titleColumn\"):\n",
    "    for i in soup.find_all('span',class_=\"secondaryInfo\"):\n",
    "        z.append(i.text)\n",
    "        \n",
    "k=[]      \n",
    "for i in z:\n",
    "    k.append(i[1:-1])\n",
    "    \n",
    "del k[100:]\n",
    "\n",
    "print(len(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7accf06f",
   "metadata": {},
   "source": [
    "Find Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0bb68e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.4  8.4  8.4  8.4  8.4  8.4  8.4  8.4  8.3  8.3  8.3  8.3  8.3  8.3  8.3  "
     ]
    }
   ],
   "source": [
    "mo=[]\n",
    "for i in soup.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "        mo.append(i.text)\n",
    "m=[]\n",
    "for i in mo:\n",
    "    m.append(i[1:-1])\n",
    "    \n",
    "for i in range(len(m)):\n",
    "    if i<15:\n",
    "        print(m[i],end='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "220079c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movies Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rocketry: The Nambi Effect</td>\n",
       "      <td>2022</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>2003</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>1979</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>1987</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>2021</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Movies Name  Year  Ratings\n",
       "0  Rocketry: The Nambi Effect  2022     8.4\n",
       "1                  Anbe Sivam  2003     8.4\n",
       "2                     Golmaal  1979     8.4\n",
       "3                     Nayakan  1987     8.4\n",
       "4                    Jai Bhim  2021     8.4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=pd.DataFrame({\"Movies Name \":h,\"Year \":k,\"Ratings\":m})\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a4a5dc",
   "metadata": {},
   "source": [
    "# 4. Write python program to display list of respected former presidents of India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c23b688b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page4 = requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "page4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7cfbb9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page4.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dca075",
   "metadata": {},
   "source": [
    "Find Name and Delete the unnecessary elements ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cad15c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "for i in soup.find_all('div',class_=\"presidentListing\"):\n",
    "    for i in soup.find_all('h3'):\n",
    "        Name.append(i.text)\n",
    "del Name[14:]\n",
    "name=[]\n",
    "for i in Name:\n",
    "    name.append(i[:-12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c61bb0",
   "metadata": {},
   "source": [
    "Find Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "690d40a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Term=[]\n",
    "for i in soup.find_all('div',class_=\"presidentListing\"):\n",
    "    for i in soup.find_all('p'):\n",
    "                Term.append(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587de636",
   "metadata": {},
   "source": [
    "Delete unneccessary element "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "b2c0d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Term:\n",
    "    if i.startswith('http:')|i.startswith('https:')|i.startswith('Copyright')|i.startswith('Page')|i.startswith('\\r'):\n",
    "        Term.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911af94e",
   "metadata": {},
   "source": [
    "Extract desired string from each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "9e90d238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25 July, 2017 to 25 July, 2022 ',\n",
       " '25 July, 2012 to 25 July, 2017 ',\n",
       " '25 July, 2007 to 25 July, 2012 ',\n",
       " '25 July, 2002 to 25 July, 2007 ',\n",
       " '25 July, 1997 to 25 July, 2002 ',\n",
       " '25 July, 1992 to 25 July, 1997 ',\n",
       " '25 July, 1987 to 25 July, 1992 ',\n",
       " '25 July, 1982 to 25 July, 1987 ',\n",
       " '25 July, 1977 to 25 July, 1982 ',\n",
       " '24 August, 1974 to 11 February, 1977',\n",
       " '3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974',\n",
       " '13 May, 1967 to 3 May, 1969',\n",
       " '13 May, 1962 to 13 May, 1967',\n",
       " '26 January, 1950 to 13 May, 1962']"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[]\n",
    "for i in Term:\n",
    "    l.append(i[16:])\n",
    "    \n",
    "del l[14:]\n",
    "l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "027d4151",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 14\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "7a024e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of President of India</th>\n",
       "      <th>Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind (b</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil (b</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan (</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name of President of India                             Term\n",
       "0          Shri Ram Nath Kovind (b  25 July, 2017 to 25 July, 2022 \n",
       "1            Shri Pranab Mukherjee  25 July, 2012 to 25 July, 2017 \n",
       "2  Smt Pratibha Devisingh Patil (b  25 July, 2007 to 25 July, 2012 \n",
       "3           DR. A.P.J. Abdul Kalam  25 July, 2002 to 25 July, 2007 \n",
       "4           Shri K. R. Narayanan (  25 July, 1997 to 25 July, 2002 "
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pres=pd.DataFrame({'Name of President of India':name,'Term':l})\n",
    "pres.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9301a62a",
   "metadata": {},
   "source": [
    "# 4. Write a python program to scrape cricket rankings from icc-cricket.com."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033b317b",
   "metadata": {},
   "source": [
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "855c0e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffceab0",
   "metadata": {},
   "source": [
    "Extract the name of the team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "b150560c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['England',\n",
       " 'New Zealand',\n",
       " 'India',\n",
       " 'Pakistan',\n",
       " 'Australia',\n",
       " 'South Africa',\n",
       " 'Bangladesh',\n",
       " 'Sri Lanka',\n",
       " 'West Indies',\n",
       " 'Afghanistan']"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=[]\n",
    "for i in soup.find_all(\"span\",class_=\"u-hide-phablet\"):\n",
    "    t.append(i.text)\n",
    "del t[10:]\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092efb7b",
   "metadata": {},
   "source": [
    "Extract matches played and points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "f2cf8855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['27',\n",
       " '3,226',\n",
       " '22',\n",
       " '2,508',\n",
       " '31',\n",
       " '3,447',\n",
       " '22',\n",
       " '2,354',\n",
       " '29',\n",
       " '3,071',\n",
       " '21',\n",
       " '2,111',\n",
       " '30',\n",
       " '2,753',\n",
       " '29',\n",
       " '2,658',\n",
       " '41',\n",
       " '2,902',\n",
       " '18',\n",
       " '1,238']"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=[]\n",
    "k=soup.find(\"td\",class_=\"rankings-block__banner--matches\")\n",
    "m.append(k.text)\n",
    "l=soup.find(\"td\",class_=\"rankings-block__banner--points\")\n",
    "m.append(l.text)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-center-text\"):\n",
    "    m.append(i.text)\n",
    "del m[20:]\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42405d6f",
   "metadata": {},
   "source": [
    "Above list contains matches played and points in alternate order. Use loop to extract both list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "36db187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches=[]\n",
    "points=[]\n",
    "for i in range(len(m)):\n",
    "    if (i%2)==0:\n",
    "        matches.append(m[i])\n",
    "    else:\n",
    "        points.append(m[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "94f13875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['27', '22', '31', '22', '29', '21', '30', '29', '41', '18']"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "4534dd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3,226',\n",
       " '2,508',\n",
       " '3,447',\n",
       " '2,354',\n",
       " '3,071',\n",
       " '2,111',\n",
       " '2,753',\n",
       " '2,658',\n",
       " '2,902',\n",
       " '1,238']"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdaae96",
   "metadata": {},
   "source": [
    "Extract ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "73ecdcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n                            119\\n                            \\n\\n',\n",
       " '114',\n",
       " '111',\n",
       " '107',\n",
       " '106',\n",
       " '101',\n",
       " '92',\n",
       " '92',\n",
       " '71',\n",
       " '69']"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=[]\n",
    "l=soup.find(\"td\",class_=\"rankings-block__banner--rating u-text-right\")\n",
    "r.append(l.text)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\"):\n",
    "    r.append(i.text)\n",
    "del r[10:]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "792ec22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>England</td>\n",
       "      <td>27</td>\n",
       "      <td>3,226</td>\n",
       "      <td>\\n                            119\\n           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>22</td>\n",
       "      <td>2,508</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>31</td>\n",
       "      <td>3,447</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>22</td>\n",
       "      <td>2,354</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>29</td>\n",
       "      <td>3,071</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Team Matches Points  \\\n",
       "0      England      27  3,226   \n",
       "1  New Zealand      22  2,508   \n",
       "2        India      31  3,447   \n",
       "3     Pakistan      22  2,354   \n",
       "4    Australia      29  3,071   \n",
       "\n",
       "                                             Ratings  \n",
       "0  \\n                            119\\n           ...  \n",
       "1                                                114  \n",
       "2                                                111  \n",
       "3                                                107  \n",
       "4                                                106  "
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Team\":t,\"Matches\":matches,\"Points\":points,\"Ratings\":r})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0fe929",
   "metadata": {},
   "source": [
    "Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "b7b3fb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>England</td>\n",
       "      <td>27</td>\n",
       "      <td>3,226</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>22</td>\n",
       "      <td>2,508</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>31</td>\n",
       "      <td>3,447</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>22</td>\n",
       "      <td>2,354</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>29</td>\n",
       "      <td>3,071</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Team Matches Points Ratings\n",
       "0      England      27  3,226     119\n",
       "1  New Zealand      22  2,508     114\n",
       "2        India      31  3,447     111\n",
       "3     Pakistan      22  2,354     107\n",
       "4    Australia      29  3,071     106"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df.replace(to_replace=[r[0]],value=\"119\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795781af",
   "metadata": {},
   "source": [
    "# b) Top 10 ODI Batsmen along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "0203acec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page5a = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "page5a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "a1802328",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page5a.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ebf1e5",
   "metadata": {},
   "source": [
    "Extract Batsman Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "276df354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Babar Azam',\n",
       " 'Rassie van der Dussen',\n",
       " 'Quinton de Kock',\n",
       " 'Imam-ul-Haq',\n",
       " 'Virat Kohli',\n",
       " 'Rohit Sharma',\n",
       " 'Jonny Bairstow',\n",
       " 'David Warner',\n",
       " 'Ross Taylor',\n",
       " 'Steve Smith']"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bat=[]\n",
    "d=soup.find(\"div\",attrs={\"data-title\":\"ODI Batting Rankings\"}).find(\"div\",attrs={\"rankings-block__top-player\"}).find(\"div\",attrs={\"rankings-block__banner--player-info\"}).find(\"div\",class_=\"rankings-block__banner--name\").get_text(strip=True,separator=\" \")\n",
    "bat.append(d)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\"):\n",
    "    bat.append(i.text)\n",
    "    \n",
    "del bat[10:]\n",
    "b=[]\n",
    "for i in bat:\n",
    "    b.append(i.translate({ord(i): None for i in '\\n'}))\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b34897",
   "metadata": {},
   "source": [
    "Extract rating and delete unnecessary elements from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d23b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[]\n",
    "e=soup.find('div',attrs={\"class\":\"rankings-block__banner--rating\"}).get_text(strip=True)\n",
    "rating.append(e)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    rating.append(i.text)\n",
    "    \n",
    "del rating[10:]\n",
    "rating\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b021b",
   "metadata": {},
   "source": [
    "Extract team name and delete unnecessary elements from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "753b3b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAK890', 'SA', 'SA', 'PAK', 'IND', 'IND', 'ENG', 'AUS', 'NZ', 'AUS']"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team=[]\n",
    "f=soup.find('div',attrs={\"class\":\"rankings-block__banner--nationality\"}).get_text(strip=True)\n",
    "team.append(f)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell nationality-logo\"):\n",
    "    team.append(i.text)\n",
    "del team[10:]\n",
    "c=[]\n",
    "for i in team:\n",
    "    c.append(i.translate({ord(i): None for i in '\\n'}))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "5dba64be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batsman_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK890</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Batsman_Name    Team Ratings\n",
       "0             Babar Azam  PAK890     890\n",
       "1  Rassie van der Dussen      SA     789\n",
       "2        Quinton de Kock      SA     784\n",
       "3            Imam-ul-Haq     PAK     779\n",
       "4            Virat Kohli     IND     744"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odi_bat=pd.DataFrame({\"Batsman_Name\":b,\"Team\":c,\"Ratings\":rating})\n",
    "odi_bat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a115106",
   "metadata": {},
   "source": [
    "Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "1f8f2622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batsman_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Batsman_Name Team Ratings\n",
       "0             Babar Azam  PAK     890\n",
       "1  Rassie van der Dussen   SA     789\n",
       "2        Quinton de Kock   SA     784\n",
       "3            Imam-ul-Haq  PAK     779\n",
       "4            Virat Kohli  IND     744"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=odi_bat.replace(to_replace=[c[0]],value=\"PAK\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ac0e58",
   "metadata": {},
   "source": [
    "# c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eba14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "page5a = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "soup = BeautifulSoup(page5a.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8942b7cd",
   "metadata": {},
   "source": [
    "Extract bowler name and delete unnecessary elements from the list. Also remove unnecessary string \"\\n\" from each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "509afe0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trent Boult',\n",
       " 'Josh Hazlewood',\n",
       " 'Mujeeb Ur Rahman',\n",
       " 'Jasprit Bumrah',\n",
       " 'Shaheen Afridi',\n",
       " 'Mohammad Nabi',\n",
       " 'Mehedi Hasan',\n",
       " 'Matt Henry',\n",
       " 'Mitchell Starc',\n",
       " 'Rashid Khan']"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ball=[]\n",
    "k=soup.find(\"div\",attrs={\"data-title\":\"ODI Bowling Rankings\"}).find(\"div\",attrs={\"rankings-block__top-player\"}).find(\"div\",attrs={\"rankings-block__banner--player-info\"}).find(\"div\",class_=\"rankings-block__banner--name\").get_text(strip=True,separator=\" \")\n",
    "ball.append(k)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\"):\n",
    "    ball.append(i.text)\n",
    "    \n",
    "\n",
    "\n",
    "del ball[1:10]\n",
    "del ball[10:]\n",
    "b=[]\n",
    "for i in ball:\n",
    "    b.append(i.translate({ord(i): None for i in '\\n'}))\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39b13ce",
   "metadata": {},
   "source": [
    "Extract ratings and delete unnecessary elements from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "8c25ab22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['775', '718', '676', '662', '661', '657', '655', '654', '653', '651']"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rat=[]\n",
    "k=soup.find(\"div\",attrs={\"data-title\":\"ODI Bowling Rankings\"}).find(\"div\",attrs={\"rankings-block__top-player\"}).find(\"div\",attrs={\"rankings-block__banner--player-info\"}).find(\"div\",class_=\"rankings-block__banner--rating\").get_text(strip=True,separator=\" \")\n",
    "rat.append(k)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    rat.append(i.text)\n",
    "    \n",
    "\n",
    "\n",
    "del rat[1:10]\n",
    "del rat[10:]\n",
    "rat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d54fc35",
   "metadata": {},
   "source": [
    "Extract team name and delete unnecessary elements from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "2515ebd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NZ 775', 'AUS', 'AFG', 'IND', 'PAK', 'AFG', 'BAN', 'NZ', 'AUS', 'AFG']"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tea=[]\n",
    "j=soup.find(\"div\",attrs={\"data-title\":\"ODI Bowling Rankings\"}).find(\"div\",attrs={\"rankings-block__top-player\"}).find(\"div\",attrs={\"rankings-block__banner--player-info\"}).find(\"div\",class_=\"rankings-block__banner--nationality\").get_text(strip=True,separator=\" \")\n",
    "tea.append(j)\n",
    "for i in soup.find_all('td',class_=\"table-body__cell nationality-logo\"):\n",
    "    tea.append(i.text)\n",
    "del tea[1:10]\n",
    "del tea[10:]\n",
    "\n",
    "c=[]\n",
    "for i in tea:\n",
    "    c.append(i.translate({ord(i): None for i in '\\n'}))\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28718c2b",
   "metadata": {},
   "source": [
    "Check the length of all 3 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "2e03ca37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(ball),len(tea),len(rat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "0b48fa48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bowler_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ 775</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bowler_Name    Team Ratings\n",
       "0       Trent Boult  NZ 775     775\n",
       "1    Josh Hazlewood     AUS     718\n",
       "2  Mujeeb Ur Rahman     AFG     676\n",
       "3    Jasprit Bumrah     IND     662\n",
       "4    Shaheen Afridi     PAK     661"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odi_ball=pd.DataFrame({\"Bowler_Name\":b,\"Team\":c,\"Ratings\":rat})\n",
    "odi_ball.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f7871f",
   "metadata": {},
   "source": [
    "Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "74e1ffd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bowler_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bowler_Name Team Ratings\n",
       "0       Trent Boult   NZ     775\n",
       "1    Josh Hazlewood  AUS     718\n",
       "2  Mujeeb Ur Rahman  AFG     676\n",
       "3    Jasprit Bumrah  IND     662\n",
       "4    Shaheen Afridi  PAK     661"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=odi_ball.replace(to_replace=[c[0]],value=\"NZ\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a5fe8f",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b9c388",
   "metadata": {},
   "source": [
    "# 6) Write a python program to scrape women cricket rankings from icc-cricket.com. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f8c95f",
   "metadata": {},
   "source": [
    "# a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64117db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e86eae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38925f97",
   "metadata": {},
   "source": [
    "Extract name of team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf1ecb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australia',\n",
       " 'South Africa',\n",
       " 'England',\n",
       " 'India',\n",
       " 'New Zealand',\n",
       " 'West Indies',\n",
       " 'Bangladesh',\n",
       " 'Pakistan',\n",
       " 'Ireland',\n",
       " 'Sri Lanka',\n",
       " 'Zimbabwe']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "for i in soup.find_all(\"span\",class_=\"u-hide-phablet\"):\n",
    "    name.append(i.text)\n",
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0dfd91",
   "metadata": {},
   "source": [
    "Extract matches played and points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ad278a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29',\n",
       " '4,837',\n",
       " '35',\n",
       " '4,157',\n",
       " '36',\n",
       " '4,205',\n",
       " '35',\n",
       " '3,732',\n",
       " '34',\n",
       " '3,342',\n",
       " '33',\n",
       " '3,014',\n",
       " '12',\n",
       " '930',\n",
       " '30',\n",
       " '1,962',\n",
       " '11',\n",
       " '516',\n",
       " '11',\n",
       " '495',\n",
       " '8',\n",
       " '0']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt=[]\n",
    "k=soup.find(\"td\",class_=\"rankings-block__banner--matches\").get_text()\n",
    "mt.append(k)\n",
    "l=soup.find(\"td\",class_=\"rankings-block__banner--points\").get_text()\n",
    "mt.append(l)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-center-text\"):\n",
    "    mt.append(i.text)\n",
    "mt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c899fd",
   "metadata": {},
   "source": [
    "The list above conatins matches played and points together in alternate order. We now separated data to get two list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55f41b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches=[]\n",
    "points=[]\n",
    "for i in range(len(mt)):\n",
    "    if (i%2)==0:\n",
    "        matches.append(mt[i])\n",
    "    else:\n",
    "        points.append(mt[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2eddbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29', '35', '36', '35', '34', '33', '12', '30', '11', '11', '8']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73a0f3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4,837',\n",
       " '4,157',\n",
       " '4,205',\n",
       " '3,732',\n",
       " '3,342',\n",
       " '3,014',\n",
       " '930',\n",
       " '1,962',\n",
       " '516',\n",
       " '495',\n",
       " '0']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3781e7e8",
   "metadata": {},
   "source": [
    "Finding rating of team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e13006",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=[]\n",
    "k=soup.find(\"td\",class_=\"rankings-block__banner--rating u-text-right\")\n",
    "ratings.append(k.text)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\"):\n",
    "    ratings.append(i.text)\n",
    "ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3ec27bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>29</td>\n",
       "      <td>4,837</td>\n",
       "      <td>\\n                            167\\n           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>35</td>\n",
       "      <td>4,157</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>36</td>\n",
       "      <td>4,205</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>35</td>\n",
       "      <td>3,732</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>34</td>\n",
       "      <td>3,342</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country Matches Points  \\\n",
       "0     Australia      29  4,837   \n",
       "1  South Africa      35  4,157   \n",
       "2       England      36  4,205   \n",
       "3         India      35  3,732   \n",
       "4   New Zealand      34  3,342   \n",
       "\n",
       "                                             Ratings  \n",
       "0  \\n                            167\\n           ...  \n",
       "1                                                119  \n",
       "2                                                117  \n",
       "3                                                107  \n",
       "4                                                 98  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\"Country\":name,\"Matches\":matches,\"Points\":points,\"Ratings\":ratings})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39866d8",
   "metadata": {},
   "source": [
    "Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "21973ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>29</td>\n",
       "      <td>4,837</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>35</td>\n",
       "      <td>4,157</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>36</td>\n",
       "      <td>4,205</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>35</td>\n",
       "      <td>3,732</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>34</td>\n",
       "      <td>3,342</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country Matches Points Ratings\n",
       "0     Australia      29  4,837     167\n",
       "1  South Africa      35  4,157     119\n",
       "2       England      36  4,205     117\n",
       "3         India      35  3,732     107\n",
       "4   New Zealand      34  3,342      98"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df.replace(to_replace=[ratings[0]],value=\"167\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de76ca7",
   "metadata": {},
   "source": [
    "# b) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3083d07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2db43a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8394f809",
   "metadata": {},
   "source": [
    "Extract name of batter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e92803b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alyssa Healy',\n",
       " 'Beth Mooney',\n",
       " 'Laura Wolvaardt',\n",
       " 'Natalie Sciver',\n",
       " 'Harmanpreet Kaur',\n",
       " 'Smriti Mandhana',\n",
       " 'Meg Lanning',\n",
       " 'Rachael Haynes',\n",
       " 'Amy Satterthwaite',\n",
       " 'Chamari Athapaththu']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "k=soup.find(\"div\",class_=\"rankings-block__banner--name\")\n",
    "name.append(k.text)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell name\"):\n",
    "        name.append(i.text)\n",
    "a=[]\n",
    "for i in name:\n",
    "    a.append(i.translate({ord(i): None for i in '\\n'}))\n",
    "    \n",
    "del a[10:]\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d955a1",
   "metadata": {},
   "source": [
    "Extract the team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6c175331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\nAUS\\n                            785\\nAUS                            785AUSSAENGINDINDAUSAUSNZSLAUSAUSSAINDWIENGSAINDSAAUSENGNZSAINDAUSAUSINDENGAUS                            785AUS                            785AUSSAENGINDINDAUSAUSNZSLAUSAUSSAINDWIENGSAINDSAAUSENGNZSAINDAUSAUSINDENGAUSSAENGINDINDAUSAUSNZSLAUSAUSSAINDWIENGSAINDSAAUSENGNZSAINDAUSAUSINDENG',\n",
       " 'AUS',\n",
       " 'SA',\n",
       " 'ENG',\n",
       " 'IND',\n",
       " 'IND',\n",
       " 'AUS',\n",
       " 'AUS',\n",
       " 'NZ',\n",
       " 'SL']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams=[]\n",
    "k=soup.find(\"div\",class_=\"rankings-block__banner--nationality\")\n",
    "teams.append(k.text)\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"):\n",
    "    teams.append(i.text)\n",
    "\n",
    "del teams[10:]\n",
    "teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b5b16",
   "metadata": {},
   "source": [
    "Extract the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "97e29394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['785', '749', '732', '725', '716', '714', '710', '701', '661', '655']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points=[]\n",
    "k=soup.find(\"div\",class_=\"rankings-block__banner--rating\")\n",
    "points.append(k.text)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\"):\n",
    "    points.append(i.text)\n",
    "    \n",
    "del points[10:]\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "32e1dfb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>\\n\\nAUS\\n                            785\\nAUS ...</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name                                            Country Ratings\n",
       "0      Alyssa Healy  \\n\\nAUS\\n                            785\\nAUS ...     785\n",
       "1       Beth Mooney                                                AUS     749\n",
       "2   Laura Wolvaardt                                                 SA     732\n",
       "3    Natalie Sciver                                                ENG     725\n",
       "4  Harmanpreet Kaur                                                IND     716"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Name\":a,\"Country\":teams,\"Ratings\":points})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04609ad0",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7c5d659f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name Country Ratings\n",
       "0      Alyssa Healy     AUS     785\n",
       "1       Beth Mooney     AUS     749\n",
       "2   Laura Wolvaardt      SA     732\n",
       "3    Natalie Sciver     ENG     725\n",
       "4  Harmanpreet Kaur     IND     716"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df.replace(to_replace=[teams[0]],value=\"AUS\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5774eb3",
   "metadata": {},
   "source": [
    "# c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e38d73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "page\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abfb89c",
   "metadata": {},
   "source": [
    "Extracts names of all rounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0240cfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hayley Matthews',\n",
       " 'Ellyse Perry',\n",
       " 'Natalie Sciver',\n",
       " 'Amelia Kerr',\n",
       " 'Marizanne Kapp',\n",
       " 'Deepti Sharma',\n",
       " 'Ashleigh Gardner',\n",
       " 'Jess Jonassen',\n",
       " 'Jhulan Goswami',\n",
       " 'Katherine Brunt']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "k=soup.find(\"div\",attrs={\"data-title\":\"ODI All-Rounder Rankings\",}).find(\"div\",class_=\"rankings-block__banner--name\")\n",
    "name.append(k.text)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell name\"):\n",
    "        name.append(i.text)\n",
    "a=[]\n",
    "for i in name:\n",
    "    a.append(i.translate({ord(i): None for i in '\\n'}))\n",
    "    \n",
    "del a[1:19]\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837765b3",
   "metadata": {},
   "source": [
    "Extract the list of teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "63318a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\nWI\\n                            380\\n',\n",
       " 'AUS',\n",
       " 'ENG',\n",
       " 'NZ',\n",
       " 'SA',\n",
       " 'IND',\n",
       " 'AUS',\n",
       " 'AUS',\n",
       " 'IND',\n",
       " 'ENG']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams=[]\n",
    "k=soup.find(\"div\",attrs={\"data-title\":\"ODI All-Rounder Rankings\",}).find(\"div\",class_=\"rankings-block__banner--nationality\")\n",
    "teams.append(k.text)\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"):\n",
    "    teams.append(i.text)\n",
    "\n",
    "del teams[1:19]\n",
    "teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b31b52",
   "metadata": {},
   "source": [
    "Extract points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c3321339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['380', '374', '357', '356', '349', '322', '270', '246', '214', '207']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points=[]\n",
    "k=soup.find(\"div\",attrs={\"data-title\":\"ODI All-Rounder Rankings\",}).find(\"div\",class_=\"rankings-block__banner--rating\")\n",
    "points.append(k.text)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\"):\n",
    "    points.append(i.text)\n",
    "    \n",
    "del points[1:19]\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "16b6c120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>\\n\\nWI\\n                            380\\n</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name                                    Country Ratings\n",
       "0  Hayley Matthews  \\n\\nWI\\n                            380\\n     380\n",
       "1     Ellyse Perry                                        AUS     374\n",
       "2   Natalie Sciver                                        ENG     357\n",
       "3      Amelia Kerr                                         NZ     356\n",
       "4   Marizanne Kapp                                         SA     349"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Name\":a,\"Country\":teams,\"Ratings\":points})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2c33bc",
   "metadata": {},
   "source": [
    "Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3c38cfdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name Country Ratings\n",
       "0  Hayley Matthews      WI     380\n",
       "1     Ellyse Perry     AUS     374\n",
       "2   Natalie Sciver     ENG     357\n",
       "3      Amelia Kerr      NZ     356\n",
       "4   Marizanne Kapp      SA     349"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df.replace(to_replace=[teams[0]],value=\"WI\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efc245d",
   "metadata": {},
   "source": [
    "# 7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "1b9469d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "page\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6549a860",
   "metadata": {},
   "source": [
    "Extract headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f9137602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elon Musk shows off humanoid robot prototype at Tesla AI Day',\n",
       " \"Cramer's lightning round: nLight is not a buy\",\n",
       " 'Cramer: Charts suggest it’s ‘way too early’ to expect the market to rebound',\n",
       " \"Cramer’s week ahead: 3 big events will set the market's tone for October\",\n",
       " \"Intel's self-driving car division Mobileye files for IPO\",\n",
       " \"Pro Picks: Watch all of Friday's big stock calls on CNBC\",\n",
       " \"Wall Street took a close look at Disney and Microsoft. Here's our take \",\n",
       " 'Donald Trump urged to tell shareholders to vote on delaying merger with SPAC',\n",
       " 'Tesla expected to show a humanoid robot demo on Friday night at AI Day 2022',\n",
       " 'Disney reaches deal with Third Point, will add former Meta exec to its board',\n",
       " 'Good riddance September: We gauge the market damage and get ready for October',\n",
       " 'EV and self-driving stocks fell 15% in September, second-worst month on record',\n",
       " 'Met Gala 2023 theme will celebrate late designer Karl Lagerfeld',\n",
       " \"Gautam Adani: How Asia's richest person gave Jeff Bezos a run for his money\",\n",
       " 'Why people are looking to Waffle House as Hurricane Ian makes landfall again',\n",
       " \"We're upgrading our rating on AbbVie amid a false report on the biopharma's guidance\",\n",
       " \"What Nike's earnings report tells us about 3 consumer stocks in our portfolio\",\n",
       " 'Here are the people who texted Elon Musk about the Twitter deal',\n",
       " \"Biden warns Putin: U.S. will defend 'every inch' of NATO territory \",\n",
       " 'American homebuyers are finding UK bargains, discounted by a weaker pound',\n",
       " 'Ohio reports third U.S. death of person with monkeypox',\n",
       " 'These money deal breakers could sour a relationship, couples say',\n",
       " \"These are the best ways to give to charity for the 'vast majority of people'\",\n",
       " 'Silicon Valley billionaires square off over support for Trump and MAGA movement',\n",
       " 'Goldman says buy puts on these stocks with deteriorating fundamentals',\n",
       " 'Over 700,000 borrowers no longer qualify for student loan relief',\n",
       " 'The beaten-up market may get a slight reprieve as the calendar turns to October',\n",
       " 'FTX is paying $51 million in cash for Voyager assets, court records show',\n",
       " '83% of workers have seen or experienced quiet firing—7 signs to look for',\n",
       " 'These beat-up stocks show signs of bottoming as rest of market falls to new lows']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=[]\n",
    "for i in soup.find_all(\"a\",class_=\"LatestNews-headline\"):\n",
    "    title.append(i.text)\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab09e5",
   "metadata": {},
   "source": [
    "Extract publishing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "62ce5131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4 Hours Ago',\n",
       " '7 Hours Ago',\n",
       " '8 Hours Ago',\n",
       " '8 Hours Ago',\n",
       " '9 Hours Ago',\n",
       " '9 Hours Ago',\n",
       " '9 Hours Ago',\n",
       " '9 Hours Ago',\n",
       " '10 Hours Ago',\n",
       " '10 Hours Ago',\n",
       " '10 Hours Ago',\n",
       " '10 Hours Ago',\n",
       " '10 Hours Ago',\n",
       " '10 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '11 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '12 Hours Ago',\n",
       " '13 Hours Ago',\n",
       " '13 Hours Ago',\n",
       " '13 Hours Ago',\n",
       " '13 Hours Ago',\n",
       " '13 Hours Ago']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time=[]\n",
    "for i in soup.find_all(\"span\",class_=\"LatestNews-wrapper\"):\n",
    "    time.append(i.text)\n",
    "time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542510d0",
   "metadata": {},
   "source": [
    "Extract url of each headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fcc0ee0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.cnbc.com/2022/09/30/elon-musk-shows-off-humanoid-robot-prototype-at-tesla-ai-day.html',\n",
       " 'https://www.cnbc.com/2022/09/30/cramers-lightning-round-nlight-is-not-a-buy.html',\n",
       " 'https://www.cnbc.com/2022/09/30/cramer-charts-suggest-its-way-too-early-for-the-market-to-rebound.html',\n",
       " 'https://www.cnbc.com/2022/09/30/cramers-week-ahead-3-events-will-set-the-markets-tone-for-october.html',\n",
       " 'https://www.cnbc.com/2022/09/30/intel-owned-mobileye-files-s-1-for-ipo.html',\n",
       " 'https://www.cnbc.com/2022/09/30/pro-picks-watch-all-of-fridays-big-stock-calls-on-cnbc.html',\n",
       " 'https://www.cnbc.com/2022/09/30/wall-street-took-a-close-look-at-disney-and-microsoft.html',\n",
       " 'https://www.cnbc.com/2022/09/30/donald-trump-truth-social-devin-nunes-digital-world-merger-delay.html',\n",
       " 'https://www.cnbc.com/2022/09/30/tesla-ai-day-2022-expect-humanoid-robot-optimus-demo.html',\n",
       " 'https://www.cnbc.com/2022/09/30/disney-reaches-deal-with-activist-investor-third-point-will-add-former-meta-executive-to-its-board.html',\n",
       " 'https://www.cnbc.com/2022/09/30/good-riddance-september-we-gauge-the-damage-and-get-ready-for-october.html',\n",
       " 'https://www.cnbc.com/2022/09/30/electric-and-autonomous-vehicle-etf-falls-15percent-in-september.html',\n",
       " 'https://www.cnbc.com/2022/09/30/met-gala-2023-theme-will-celebrate-late-designer-karl-lagerfeld.html',\n",
       " 'https://www.cnbc.com/2022/09/30/gautam-adani-how-asias-richest-person-gave-bezos-a-run-for-his-money.html',\n",
       " 'https://www.cnbc.com/2022/09/30/fema-waffle-house-index-hurricane-ian-makes-landfall-again.html',\n",
       " 'https://www.cnbc.com/2022/09/30/were-upgrading-our-rating-on-abbvie-amid-a-false-report-on-the-biopharmas-guidance.html',\n",
       " 'https://www.cnbc.com/2022/09/30/what-nikes-earnings-report-tells-us-about-3-consumer-stocks-in-our-portfolio.html',\n",
       " 'https://www.cnbc.com/2022/09/30/who-texted-elon-musk-to-get-involved-or-offer-advice-on-twitter-deal.html',\n",
       " 'https://www.cnbc.com/2022/09/30/biden-warns-putin-on-nato-threat-as-russia-annexes-ukraine-regions.html',\n",
       " 'https://www.cnbc.com/2022/09/30/american-homebuyers-find-uk-bargains-discounted-by-a-weaker-pound.html',\n",
       " 'https://www.cnbc.com/2022/09/30/ohio-reports-third-us-death-of-person-with-monkeypox.html',\n",
       " 'https://www.cnbc.com/2022/09/30/these-money-deal-breakers-could-sour-a-relationship-couples-say.html',\n",
       " 'https://www.cnbc.com/2022/09/30/heres-how-to-pick-the-best-charitable-giving-strategy.html',\n",
       " 'https://www.cnbc.com/2022/09/30/silicon-valley-billionaires-duel-over-trump-midterm-elections.html',\n",
       " 'https://www.cnbc.com/2022/09/30/goldman-says-buy-puts-on-these-stocks-with-deteriorating-fundamentals-in-this-bear-market.html',\n",
       " 'https://www.cnbc.com/2022/09/30/over-700000-borrowers-no-longer-qualify-for-student-loan-relief.html',\n",
       " 'https://www.cnbc.com/2022/09/30/the-beaten-down-stock-market-may-get-a-slight-reprieve-as-the-calendar-turns-to-october.html',\n",
       " 'https://www.cnbc.com/2022/09/30/ftx-is-paying-51-million-in-cash-for-voyager-assets-court-records-.html',\n",
       " 'https://www.cnbc.com/2022/09/30/7-signs-of-quiet-firing-to-look-for-at-work.html',\n",
       " 'https://www.cnbc.com/2022/09/30/these-beaten-up-stocks-show-signs-of-bottoming-as-rest-of-market-falls-to-new-lows.html']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link=[]\n",
    "for i in soup.find_all(\"a\",class_=\"LatestNews-headline\"):\n",
    "    link.append(i.get(\"href\"))\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "95235d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(title),len(time),len(link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "aa814516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Published</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elon Musk shows off humanoid robot prototype a...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/30/elon-musk-show...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cramer's lightning round: nLight is not a buy</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/30/cramers-lightn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cramer: Charts suggest it’s ‘way too early’ to...</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/30/cramer-charts-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cramer’s week ahead: 3 big events will set the...</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/30/cramers-week-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intel's self-driving car division Mobileye fil...</td>\n",
       "      <td>9 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/30/intel-owned-mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline    Published  \\\n",
       "0  Elon Musk shows off humanoid robot prototype a...  4 Hours Ago   \n",
       "1      Cramer's lightning round: nLight is not a buy  7 Hours Ago   \n",
       "2  Cramer: Charts suggest it’s ‘way too early’ to...  8 Hours Ago   \n",
       "3  Cramer’s week ahead: 3 big events will set the...  8 Hours Ago   \n",
       "4  Intel's self-driving car division Mobileye fil...  9 Hours Ago   \n",
       "\n",
       "                                                Link  \n",
       "0  https://www.cnbc.com/2022/09/30/elon-musk-show...  \n",
       "1  https://www.cnbc.com/2022/09/30/cramers-lightn...  \n",
       "2  https://www.cnbc.com/2022/09/30/cramer-charts-...  \n",
       "3  https://www.cnbc.com/2022/09/30/cramers-week-a...  \n",
       "4  https://www.cnbc.com/2022/09/30/intel-owned-mo...  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Headline\":title,\"Published\":time,\"Link\":link})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026844fa",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f818df9",
   "metadata": {},
   "source": [
    "# 8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6e2c03d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "page\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3243f30",
   "metadata": {},
   "source": [
    "Extract title of research papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e012b8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reward is enough',\n",
       " 'Making sense of raw input',\n",
       " 'Law and logic: A review from an argumentation perspective',\n",
       " 'Creativity and artificial intelligence',\n",
       " 'Artificial cognition for social human–robot interaction: An implementation',\n",
       " 'Explanation in artificial intelligence: Insights from the social sciences',\n",
       " 'Making sense of sensory input',\n",
       " 'Conflict-based search for optimal multi-agent pathfinding',\n",
       " 'Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning',\n",
       " 'The Hanabi challenge: A new frontier for AI research',\n",
       " 'Evaluating XAI: A comparison of rule-based and example-based explanations',\n",
       " 'Argumentation in artificial intelligence',\n",
       " 'Algorithms for computing strategies in two-player simultaneous move games',\n",
       " 'Multiple object tracking: A literature review',\n",
       " 'Selection of relevant features and examples in machine learning',\n",
       " 'A survey of inverse reinforcement learning: Challenges, methods and progress',\n",
       " 'Explaining individual predictions when features are dependent: More accurate approximations to Shapley values',\n",
       " 'A review of possible effects of cognitive biases on interpretation of rule-based machine learning models',\n",
       " 'Integrating social power into the decision-making of cognitive agents',\n",
       " \"“That's (not) the output I expected!” On the role of end user expectations in creating explanations of AI systems\",\n",
       " 'Explaining black-box classifiers using post-hoc explanations-by-example: The effect of explanations and error-rates in XAI user studies',\n",
       " 'Algorithm runtime prediction: Methods & evaluation',\n",
       " 'Wrappers for feature subset selection',\n",
       " 'Commonsense visual sensemaking for autonomous driving – On generalised neurosymbolic online abduction integrating vision and semantics',\n",
       " 'Quantum computation, quantum theory and AI']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=[]\n",
    "for i in soup.find_all(\"a\",class_=\"sc-5smygv-0 nrDZj\"):\n",
    "    title.append(i.text)\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bf9a0e",
   "metadata": {},
   "source": [
    "Extract author of each research paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "072e2168",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=[]\n",
    "a=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "34164402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Silver David Singh Satinder Precup Doina Sutton Richard S. ',\n",
       " 'Evans Richard Bošnjak Matko and 5 more',\n",
       " 'Prakken Henry Sartor Giovanni ',\n",
       " 'Boden Margaret A. ',\n",
       " 'Lemaignan Séverin Warnier Mathieu and 3 more',\n",
       " 'Miller Tim ',\n",
       " 'Evans Richard Hernández-Orallo José and 3 more',\n",
       " 'Sharon Guni Stern Roni Felner Ariel Sturtevant Nathan R. ',\n",
       " 'Sutton Richard S. Precup Doina Singh Satinder ',\n",
       " 'Bard Nolan Foerster Jakob N. and 13 more',\n",
       " 'van der Waa Jasper Nieuwburg Elisabeth Cremers Anita Neerincx Mark ',\n",
       " 'Bench-Capon T.J.M. Dunne Paul E. ',\n",
       " 'Bošanský Branislav Lisý Viliam and 3 more',\n",
       " 'Luo Wenhan Xing Junliang and 4 more',\n",
       " 'Blum Avrim L. Langley Pat ',\n",
       " 'Arora Saurabh Doshi Prashant ',\n",
       " 'Aas Kjersti Jullum Martin Løland Anders ',\n",
       " 'Kliegr Tomáš Bahník Štěpán Fürnkranz Johannes ',\n",
       " 'Pereira Gonçalo Prada Rui Santos Pedro A. ',\n",
       " 'Riveiro Maria Thill Serge ',\n",
       " 'Kenny Eoin M. Ford Courtney Quinn Molly Keane Mark T. ',\n",
       " 'Hutter Frank Xu Lin Hoos Holger H. Leyton-Brown Kevin ',\n",
       " 'Kohavi Ron John George H. ',\n",
       " 'Suchan Jakob Bhatt Mehul Varadarajan Srikrishna ',\n",
       " 'Ying Mingsheng ']"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i in soup.find_all(\"span\",class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    z.append(i.text)\n",
    "\n",
    "    for i in author:\n",
    "        a.append(i.translate({ord(i):None for i in ','}))\n",
    "del a[25:]\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6c1096",
   "metadata": {},
   "source": [
    "Extract published date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "3abc5503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['October 2021',\n",
       " 'October 2021',\n",
       " 'October 2015',\n",
       " 'August 1998',\n",
       " 'June 2017',\n",
       " 'February 2019',\n",
       " 'April 2021',\n",
       " 'February 2015',\n",
       " 'August 1999',\n",
       " 'March 2020',\n",
       " 'February 2021',\n",
       " 'October 2007',\n",
       " 'August 2016',\n",
       " 'April 2021',\n",
       " 'December 1997',\n",
       " 'August 2021',\n",
       " 'September 2021',\n",
       " 'June 2021',\n",
       " 'December 2016',\n",
       " 'September 2021',\n",
       " 'May 2021',\n",
       " 'January 2014',\n",
       " 'December 1997',\n",
       " 'October 2021',\n",
       " 'February 2010']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date=[]\n",
    "for i in soup.find_all(\"span\",class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "    date.append(i.text)\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eaf596",
   "metadata": {},
   "source": [
    "Extract url of each research paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "04aaba48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.sciencedirect.com/science/article/pii/S0004370221000862',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000722',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370215000910',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370298000551',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300790',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370218305988',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301855',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370214001386',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370299000521',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370219300116',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301533',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370207000793',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300285',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301958',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370297000635',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000515',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000539',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000096',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300868',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000588',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000102',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370213001082',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S000437029700043X',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000734',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370209001398']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=[]\n",
    "for i in soup.find_all(\"a\",class_=\"sc-5smygv-0 nrDZj\"):\n",
    "    url.append(i.get(\"href\"))\n",
    "url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "d41562fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Published</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver David Singh Satinder Precup Doina Sutto...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans Richard Bošnjak Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken Henry Sartor Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan Séverin Warnier Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                   Reward is enough   \n",
       "1                          Making sense of raw input   \n",
       "2  Law and logic: A review from an argumentation ...   \n",
       "3             Creativity and artificial intelligence   \n",
       "4  Artificial cognition for social human–robot in...   \n",
       "\n",
       "                                              Author     Published  \\\n",
       "0  Silver David Singh Satinder Precup Doina Sutto...  October 2021   \n",
       "1             Evans Richard Bošnjak Matko and 5 more  October 2021   \n",
       "2                     Prakken Henry Sartor Giovanni   October 2015   \n",
       "3                                 Boden Margaret A.    August 1998   \n",
       "4       Lemaignan Séverin Warnier Mathieu and 3 more     June 2017   \n",
       "\n",
       "                                                Link  \n",
       "0  https://www.sciencedirect.com/science/article/...  \n",
       "1  https://www.sciencedirect.com/science/article/...  \n",
       "2  https://www.sciencedirect.com/science/article/...  \n",
       "3  https://www.sciencedirect.com/science/article/...  \n",
       "4  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Title\":title,\"Author\":a,\"Published\":date,\"Link\":url})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122c0790",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419adee1",
   "metadata": {},
   "source": [
    "# 9) Write a python program to scrape mentioned details from dineout.co.in :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2e1ab863",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "page\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a231fb5",
   "metadata": {},
   "source": [
    "Extract name of each restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "dd8666b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Castle Barbeque',\n",
       " 'Jungle Jamboree',\n",
       " 'Castle Barbeque',\n",
       " 'Cafe Knosh',\n",
       " 'The Barbeque Company',\n",
       " 'India Grill',\n",
       " 'Delhi Barbeque',\n",
       " 'The Monarch - Bar Be Que Village',\n",
       " 'Indian Grill Room']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=[]\n",
    "for i in soup.find_all(\"a\",class_=\"restnt-name ellipsis\"):\n",
    "    res.append(i.text)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3901fc",
   "metadata": {},
   "source": [
    "Extract cuisine list of each restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "34098c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chinese, North Indian',\n",
       " 'North Indian, Asian, Italian',\n",
       " 'Chinese, North Indian',\n",
       " 'Italian, Continental',\n",
       " 'North Indian, Chinese',\n",
       " 'North Indian, Italian',\n",
       " 'North Indian',\n",
       " 'North Indian',\n",
       " 'North Indian, Mughlai']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=[]\n",
    "k=[]\n",
    "for i in soup.find_all(\"span\",class_=\"double-line-ellipsis\"):\n",
    "    c.append(i.text)\n",
    "\n",
    "for i in c:\n",
    "        k.append(i[25:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152bf5f5",
   "metadata": {},
   "source": [
    "Extract the location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "4e960bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Connaught Place, Central Delhi',\n",
       " '3CS Mall,Lajpat Nagar - 3, South Delhi',\n",
       " 'Pacific Mall,Tagore Garden, West Delhi',\n",
       " 'The Leela Ambience Convention Hotel,Shahdara, East Delhi',\n",
       " 'Gardens Galleria,Sector 38A, Noida',\n",
       " 'Hilton Garden Inn,Saket, South Delhi',\n",
       " 'Taurus Sarovar Portico,Mahipalpur, South Delhi',\n",
       " 'Indirapuram Habitat Centre,Indirapuram, Ghaziabad',\n",
       " 'Suncity Business Tower,Golf Course Road, Gurgaon']"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc=[]\n",
    "for i in soup.find_all(\"div\",class_=\"restnt-loc ellipsis\"):\n",
    "    loc.append(i.text)\n",
    "loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a270a9b4",
   "metadata": {},
   "source": [
    "Extract the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c934ce68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.1', '3.9', '3.9', '4.3', '4', '3.9', '3.6', '3.8', '4.3']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "for i in soup.find_all(\"div\",class_=\"restnt-rating rating-4\"):\n",
    "    rating.append(i.text)\n",
    "rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d72b23",
   "metadata": {},
   "source": [
    "Extract url of each restaurant on the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "7af9c84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/k/b/p86792-16062953735fbe1f4d3fb7e.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/p/m/p59633-166088382462ff137009010.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/j/o/p38113-15959192065f1fcb666130c.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/p/m/p406-15438184745c04ccea491bc.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/7/p/k/p79307-16051787755fad1597f2bf9.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/v/t/p2687-1482477169585cce712b90f.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/d/i/p52501-1661855212630de5eceb6d2.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/n/o/p34822-15599107305cfa594a13c24.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/y/f/p549-165000147262590640c0afc.jpg?tr=tr:n-medium']"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=[]\n",
    "for i in soup.find_all(\"img\",class_=\"no-img\"):\n",
    "    url.append(i.get(\"data-src\"))\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "bca1223c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name                       Cuisine  \\\n",
       "0       Castle Barbeque         Chinese, North Indian   \n",
       "1       Jungle Jamboree  North Indian, Asian, Italian   \n",
       "2       Castle Barbeque         Chinese, North Indian   \n",
       "3            Cafe Knosh          Italian, Continental   \n",
       "4  The Barbeque Company         North Indian, Chinese   \n",
       "\n",
       "                                            Location  \\\n",
       "0                     Connaught Place, Central Delhi   \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi   \n",
       "2             Pacific Mall,Tagore Garden, West Delhi   \n",
       "3  The Leela Ambience Convention Hotel,Shahdara, ...   \n",
       "4                 Gardens Galleria,Sector 38A, Noida   \n",
       "\n",
       "                                               Image  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Name\":res,\"Cuisine\":k,\"Location\":loc,\"Image\":url})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba033d9",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7270b44",
   "metadata": {},
   "source": [
    "# 10) Write a python program to scrape the details of top publications from Google Scholar from https://scholar.google.com/citations?view_op=top_venues&hl=en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "3660ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "page\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d4833",
   "metadata": {},
   "source": [
    "Extract ranking of each publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "95b7b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "for i in soup.find_all(\"td\",class_=\"gsc_mvt_p\"):\n",
    "    rank.append(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e6ddc2",
   "metadata": {},
   "source": [
    "Extract title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "36e42c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "for i in soup.find_all(\"td\",class_=\"gsc_mvt_t\"):\n",
    "    title.append(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35482704",
   "metadata": {},
   "source": [
    "Extract \"h5-index\" and \"h5-median\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "73cdeb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=[]\n",
    "for i in soup.find_all(\"td\",class_=\"gsc_mvt_n\"):\n",
    "    k.append(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df33fd03",
   "metadata": {},
   "source": [
    "Extracted k list contains both \"h5-index\" and \"h5-median\" in alternate order. Use loop to separate both into 2 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "67aff68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "h=[]\n",
    "for i in range(len(k)):\n",
    "    if(i%2)==0:\n",
    "        l.append(k[i])\n",
    "    else:\n",
    "        h.append(k[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feed909",
   "metadata": {},
   "source": [
    "Delete the unnecessary elements on both list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "5f4b5862",
   "metadata": {},
   "outputs": [],
   "source": [
    "del l[100:]\n",
    "del h[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "15e9f75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Title</th>\n",
       "      <th>h5-index</th>\n",
       "      <th>h5-median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank                                              Title h5-index h5-median\n",
       "0   1.                                             Nature      444       667\n",
       "1   2.                The New England Journal of Medicine      432       780\n",
       "2   3.                                            Science      401       614\n",
       "3   4.  IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "4   5.                                         The Lancet      354       635"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Rank\":rank,\"Title\":title,\"h5-index\":l,\"h5-median\":h})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5662055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
